{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56d2aed",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-01T13:47:58.478502Z",
     "iopub.status.busy": "2023-05-01T13:47:58.477797Z",
     "iopub.status.idle": "2023-05-01T13:48:04.683439Z",
     "shell.execute_reply": "2023-05-01T13:48:04.682326Z"
    },
    "papermill": {
     "duration": 6.212407,
     "end_time": "2023-05-01T13:48:04.686290",
     "exception": false,
     "start_time": "2023-05-01T13:47:58.473883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db3f0b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T13:48:04.691817Z",
     "iopub.status.busy": "2023-05-01T13:48:04.691211Z",
     "iopub.status.idle": "2023-05-01T13:48:17.467527Z",
     "shell.execute_reply": "2023-05-01T13:48:17.466136Z"
    },
    "papermill": {
     "duration": 12.783746,
     "end_time": "2023-05-01T13:48:17.472086",
     "exception": false,
     "start_time": "2023-05-01T13:48:04.688340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3960 images belonging to 8 classes.\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "Found 1130 images belonging to 8 classes.\n",
      "Found 575 images belonging to 8 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Set the input shape\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "# Define the number of classes\n",
    "NUM_CLASSES = 8\n",
    "\n",
    "# Define the batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Define the number of epochs\n",
    "EPOCHS = 50\n",
    "\n",
    "# Define the paths to the train, validation, and test directories\n",
    "TRAIN_DIR = \"/kaggle/input/preprocessed-dataset/dataset-split/train\"\n",
    "VAL_DIR = \"/kaggle/input/preprocessed-dataset/dataset-split/val\"\n",
    "TEST_DIR = \"/kaggle/input/preprocessed-dataset/dataset-split/test\"\n",
    "\n",
    "# Define the data augmentation parameters\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Define the training dataset generator\n",
    "train_generator = data_augmentation.flow_from_directory(\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size=INPUT_SHAPE[:2],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "for i in train_generator:\n",
    "    print(i[1])\n",
    "    break\n",
    "\n",
    "# Define the validation dataset generator\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "    directory=VAL_DIR,\n",
    "    target_size=INPUT_SHAPE[:2],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Define the test dataset generator\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    directory=TEST_DIR,\n",
    "    target_size=INPUT_SHAPE[:2],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Load the ResNet50 model pre-trained on ImageNet\n",
    "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "resnet_output = resnet.layers[-1].output\n",
    "resnet_output = layers.GlobalAveragePooling2D()(resnet_output)\n",
    "resnet_output = layers.Reshape((1, 1, 2048))(resnet_output)\n",
    "resnet_model = Model(inputs=resnet.input, outputs=resnet_output)\n",
    "\n",
    "# Set the ResNet layers to be non-trainable\n",
    "for layer in resnet.layers[:-13]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define the ResNet-50 model\n",
    "model = keras.Sequential([\n",
    "    resnet_model,  # Added the ResNet50 model here\n",
    "    layers.Flatten(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model with a learning rate of 0.001\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0002)\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e370f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T13:48:17.495748Z",
     "iopub.status.busy": "2023-05-01T13:48:17.494978Z",
     "iopub.status.idle": "2023-05-01T13:48:17.543897Z",
     "shell.execute_reply": "2023-05-01T13:48:17.542935Z"
    },
    "papermill": {
     "duration": 0.05961,
     "end_time": "2023-05-01T13:48:17.547807",
     "exception": false,
     "start_time": "2023-05-01T13:48:17.488197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 1, 1, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2048)             8192      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,651,144\n",
      "Trainable params: 5,528,072\n",
      "Non-trainable params: 19,123,072\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath = \"/kaggle/working/CNN.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f272e0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T13:48:17.563418Z",
     "iopub.status.busy": "2023-05-01T13:48:17.563014Z",
     "iopub.status.idle": "2023-05-01T14:59:32.007213Z",
     "shell.execute_reply": "2023-05-01T14:59:32.006171Z"
    },
    "papermill": {
     "duration": 4274.455019,
     "end_time": "2023-05-01T14:59:32.010155",
     "exception": false,
     "start_time": "2023-05-01T13:48:17.555136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 10.8816 - accuracy: 0.1800\n",
      "Epoch 1: loss improved from inf to 10.88159, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 94s 672ms/step - loss: 10.8816 - accuracy: 0.1800 - val_loss: 9.8858 - val_accuracy: 0.2571\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 9.9416 - accuracy: 0.2485\n",
      "Epoch 2: loss improved from 10.88159 to 9.94159, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 71s 580ms/step - loss: 9.9416 - accuracy: 0.2485 - val_loss: 9.6380 - val_accuracy: 0.3384\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 9.1893 - accuracy: 0.2839\n",
      "Epoch 3: loss improved from 9.94159 to 9.18929, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 602ms/step - loss: 9.1893 - accuracy: 0.2839 - val_loss: 8.7303 - val_accuracy: 0.2973\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 8.5724 - accuracy: 0.3065\n",
      "Epoch 4: loss improved from 9.18929 to 8.57244, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 602ms/step - loss: 8.5724 - accuracy: 0.3065 - val_loss: 8.0282 - val_accuracy: 0.3500\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 7.9513 - accuracy: 0.3243\n",
      "Epoch 5: loss improved from 8.57244 to 7.95129, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 75s 606ms/step - loss: 7.9513 - accuracy: 0.3243 - val_loss: 7.5146 - val_accuracy: 0.4009\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 7.3529 - accuracy: 0.3483\n",
      "Epoch 6: loss improved from 7.95129 to 7.35294, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 601ms/step - loss: 7.3529 - accuracy: 0.3483 - val_loss: 6.8948 - val_accuracy: 0.3732\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 6.7996 - accuracy: 0.3758\n",
      "Epoch 7: loss improved from 7.35294 to 6.79959, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 71s 580ms/step - loss: 6.7996 - accuracy: 0.3758 - val_loss: 6.3361 - val_accuracy: 0.4250\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 6.2878 - accuracy: 0.3900\n",
      "Epoch 8: loss improved from 6.79959 to 6.28778, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 6.2878 - accuracy: 0.3900 - val_loss: 6.0388 - val_accuracy: 0.4045\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 5.7988 - accuracy: 0.4035\n",
      "Epoch 9: loss improved from 6.28778 to 5.79884, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 73s 596ms/step - loss: 5.7988 - accuracy: 0.4035 - val_loss: 5.3719 - val_accuracy: 0.4518\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 5.4117 - accuracy: 0.3997\n",
      "Epoch 10: loss improved from 5.79884 to 5.41171, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 91s 739ms/step - loss: 5.4117 - accuracy: 0.3997 - val_loss: 4.9901 - val_accuracy: 0.4420\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 4.9997 - accuracy: 0.4246\n",
      "Epoch 11: loss improved from 5.41171 to 4.99965, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 87s 712ms/step - loss: 4.9997 - accuracy: 0.4246 - val_loss: 4.7553 - val_accuracy: 0.4107\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 4.6270 - accuracy: 0.4369\n",
      "Epoch 12: loss improved from 4.99965 to 4.62696, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 91s 739ms/step - loss: 4.6270 - accuracy: 0.4369 - val_loss: 4.4408 - val_accuracy: 0.4545\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 4.2791 - accuracy: 0.4450\n",
      "Epoch 13: loss improved from 4.62696 to 4.27908, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 4.2791 - accuracy: 0.4450 - val_loss: 4.0344 - val_accuracy: 0.4759\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 3.9618 - accuracy: 0.4646\n",
      "Epoch 14: loss improved from 4.27908 to 3.96175, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 3.9618 - accuracy: 0.4646 - val_loss: 3.8364 - val_accuracy: 0.4768\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 3.7005 - accuracy: 0.4661\n",
      "Epoch 15: loss improved from 3.96175 to 3.70054, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 76s 615ms/step - loss: 3.7005 - accuracy: 0.4661 - val_loss: 3.4409 - val_accuracy: 0.4920\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 3.4427 - accuracy: 0.4781\n",
      "Epoch 16: loss improved from 3.70054 to 3.44273, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 3.4427 - accuracy: 0.4781 - val_loss: 3.3341 - val_accuracy: 0.4696\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 3.2185 - accuracy: 0.4847\n",
      "Epoch 17: loss improved from 3.44273 to 3.21852, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 72s 587ms/step - loss: 3.2185 - accuracy: 0.4847 - val_loss: 3.0176 - val_accuracy: 0.5063\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 3.0356 - accuracy: 0.4809\n",
      "Epoch 18: loss improved from 3.21852 to 3.03557, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 601ms/step - loss: 3.0356 - accuracy: 0.4809 - val_loss: 2.9031 - val_accuracy: 0.4830\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 2.8218 - accuracy: 0.5015\n",
      "Epoch 19: loss improved from 3.03557 to 2.82183, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 75s 606ms/step - loss: 2.8218 - accuracy: 0.5015 - val_loss: 2.7745 - val_accuracy: 0.4920\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 2.6675 - accuracy: 0.5094\n",
      "Epoch 20: loss improved from 2.82183 to 2.66752, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 604ms/step - loss: 2.6675 - accuracy: 0.5094 - val_loss: 2.5673 - val_accuracy: 0.5134\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 2.4817 - accuracy: 0.5270\n",
      "Epoch 21: loss improved from 2.66752 to 2.48169, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 77s 629ms/step - loss: 2.4817 - accuracy: 0.5270 - val_loss: 2.3873 - val_accuracy: 0.5429\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 2.3544 - accuracy: 0.5288\n",
      "Epoch 22: loss improved from 2.48169 to 2.35443, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 2.3544 - accuracy: 0.5288 - val_loss: 2.4668 - val_accuracy: 0.4804\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 2.2417 - accuracy: 0.5328\n",
      "Epoch 23: loss improved from 2.35443 to 2.24174, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 605ms/step - loss: 2.2417 - accuracy: 0.5328 - val_loss: 2.3564 - val_accuracy: 0.5036\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 2.0929 - accuracy: 0.5476\n",
      "Epoch 24: loss improved from 2.24174 to 2.09290, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 85s 694ms/step - loss: 2.0929 - accuracy: 0.5476 - val_loss: 2.1940 - val_accuracy: 0.5277\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 2.0005 - accuracy: 0.5486\n",
      "Epoch 25: loss improved from 2.09290 to 2.00054, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 605ms/step - loss: 2.0005 - accuracy: 0.5486 - val_loss: 2.0341 - val_accuracy: 0.5089\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.9423 - accuracy: 0.5573\n",
      "Epoch 26: loss improved from 2.00054 to 1.94230, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 605ms/step - loss: 1.9423 - accuracy: 0.5573 - val_loss: 2.0339 - val_accuracy: 0.5250\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.8205 - accuracy: 0.5703\n",
      "Epoch 27: loss improved from 1.94230 to 1.82048, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 76s 618ms/step - loss: 1.8205 - accuracy: 0.5703 - val_loss: 1.9294 - val_accuracy: 0.5259\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.7451 - accuracy: 0.5771\n",
      "Epoch 28: loss improved from 1.82048 to 1.74513, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 77s 626ms/step - loss: 1.7451 - accuracy: 0.5771 - val_loss: 1.9124 - val_accuracy: 0.5277\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.7066 - accuracy: 0.5764\n",
      "Epoch 29: loss improved from 1.74513 to 1.70659, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 1.7066 - accuracy: 0.5764 - val_loss: 1.8299 - val_accuracy: 0.5312\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.6124 - accuracy: 0.5901\n",
      "Epoch 30: loss improved from 1.70659 to 1.61235, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 72s 583ms/step - loss: 1.6124 - accuracy: 0.5901 - val_loss: 2.1641 - val_accuracy: 0.5089\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.5450 - accuracy: 0.5978\n",
      "Epoch 31: loss improved from 1.61235 to 1.54503, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 605ms/step - loss: 1.5450 - accuracy: 0.5978 - val_loss: 1.9113 - val_accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.5046 - accuracy: 0.6085\n",
      "Epoch 32: loss improved from 1.54503 to 1.50458, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 73s 593ms/step - loss: 1.5046 - accuracy: 0.6085 - val_loss: 1.7533 - val_accuracy: 0.5250\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.4340 - accuracy: 0.6128\n",
      "Epoch 33: loss improved from 1.50458 to 1.43400, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 75s 612ms/step - loss: 1.4340 - accuracy: 0.6128 - val_loss: 1.8931 - val_accuracy: 0.5286\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.4236 - accuracy: 0.6130\n",
      "Epoch 34: loss improved from 1.43400 to 1.42363, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 76s 613ms/step - loss: 1.4236 - accuracy: 0.6130 - val_loss: 1.9395 - val_accuracy: 0.4696\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.3765 - accuracy: 0.6199\n",
      "Epoch 35: loss improved from 1.42363 to 1.37647, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 604ms/step - loss: 1.3765 - accuracy: 0.6199 - val_loss: 1.6303 - val_accuracy: 0.5545\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.3361 - accuracy: 0.6337\n",
      "Epoch 36: loss improved from 1.37647 to 1.33609, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 75s 604ms/step - loss: 1.3361 - accuracy: 0.6337 - val_loss: 1.6504 - val_accuracy: 0.5446\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.3189 - accuracy: 0.6380\n",
      "Epoch 37: loss improved from 1.33609 to 1.31892, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 604ms/step - loss: 1.3189 - accuracy: 0.6380 - val_loss: 2.2512 - val_accuracy: 0.4714\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.2843 - accuracy: 0.6372\n",
      "Epoch 38: loss improved from 1.31892 to 1.28433, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 74s 604ms/step - loss: 1.2843 - accuracy: 0.6372 - val_loss: 1.8192 - val_accuracy: 0.5125\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.2459 - accuracy: 0.6591\n",
      "Epoch 39: loss improved from 1.28433 to 1.24593, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 85s 693ms/step - loss: 1.2459 - accuracy: 0.6591 - val_loss: 1.7659 - val_accuracy: 0.5027\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.2422 - accuracy: 0.6604\n",
      "Epoch 40: loss improved from 1.24593 to 1.24219, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 77s 626ms/step - loss: 1.2422 - accuracy: 0.6604 - val_loss: 1.6525 - val_accuracy: 0.5339\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.2048 - accuracy: 0.6647\n",
      "Epoch 41: loss improved from 1.24219 to 1.20479, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 75s 611ms/step - loss: 1.2048 - accuracy: 0.6647 - val_loss: 1.7501 - val_accuracy: 0.5420\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.2165 - accuracy: 0.6571\n",
      "Epoch 42: loss did not improve from 1.20479\n",
      "123/123 [==============================] - 75s 606ms/step - loss: 1.2165 - accuracy: 0.6571 - val_loss: 1.7800 - val_accuracy: 0.5196\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.1605 - accuracy: 0.6820\n",
      "Epoch 43: loss improved from 1.20479 to 1.16048, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 76s 614ms/step - loss: 1.1605 - accuracy: 0.6820 - val_loss: 1.8496 - val_accuracy: 0.4625\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.1439 - accuracy: 0.6774\n",
      "Epoch 44: loss improved from 1.16048 to 1.14391, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 82s 671ms/step - loss: 1.1439 - accuracy: 0.6774 - val_loss: 1.7031 - val_accuracy: 0.5196\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.1705 - accuracy: 0.6696\n",
      "Epoch 45: loss did not improve from 1.14391\n",
      "123/123 [==============================] - 82s 667ms/step - loss: 1.1705 - accuracy: 0.6696 - val_loss: 1.7408 - val_accuracy: 0.5366\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.0789 - accuracy: 0.7001\n",
      "Epoch 46: loss improved from 1.14391 to 1.07885, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 83s 672ms/step - loss: 1.0789 - accuracy: 0.7001 - val_loss: 1.8178 - val_accuracy: 0.4902\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.1005 - accuracy: 0.6970\n",
      "Epoch 47: loss did not improve from 1.07885\n",
      "123/123 [==============================] - 80s 651ms/step - loss: 1.1005 - accuracy: 0.6970 - val_loss: 1.7025 - val_accuracy: 0.5080\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.0839 - accuracy: 0.6991\n",
      "Epoch 48: loss did not improve from 1.07885\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 1.0839 - accuracy: 0.6991 - val_loss: 1.5191 - val_accuracy: 0.5518\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.0525 - accuracy: 0.7151\n",
      "Epoch 49: loss improved from 1.07885 to 1.05250, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 79s 643ms/step - loss: 1.0525 - accuracy: 0.7151 - val_loss: 1.6951 - val_accuracy: 0.5312\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.0471 - accuracy: 0.7054\n",
      "Epoch 50: loss improved from 1.05250 to 1.04713, saving model to /kaggle/working/CNN.h5\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 1.0471 - accuracy: 0.7054 - val_loss: 1.5108 - val_accuracy: 0.5598\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size, \n",
    "    epochs=50, \n",
    "    validation_data=val_generator, \n",
    "    validation_steps=val_generator.n // val_generator.batch_size,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832717ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-01T14:59:32.689801Z",
     "iopub.status.busy": "2023-05-01T14:59:32.689441Z",
     "iopub.status.idle": "2023-05-01T14:59:45.504905Z",
     "shell.execute_reply": "2023-05-01T14:59:45.502886Z"
    },
    "papermill": {
     "duration": 13.158754,
     "end_time": "2023-05-01T14:59:45.507343",
     "exception": false,
     "start_time": "2023-05-01T14:59:32.348589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 7s 381ms/step - loss: 1.5062 - accuracy: 0.5426\n",
      "Test loss: 1.5061990022659302\n",
      "Test accuracy: 0.5426086783409119\n",
      "18/18 [==============================] - 5s 216ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68        91\n",
      "           1       0.67      0.63      0.65        97\n",
      "           2       0.91      0.24      0.38        42\n",
      "           3       0.58      0.46      0.52        82\n",
      "           4       0.51      0.44      0.47        89\n",
      "           5       0.47      0.39      0.42        44\n",
      "           6       0.40      0.52      0.45        94\n",
      "           7       0.46      0.92      0.61        36\n",
      "\n",
      "    accuracy                           0.54       575\n",
      "   macro avg       0.58      0.54      0.52       575\n",
      "weighted avg       0.57      0.54      0.54       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# Generate predictions on the test set\n",
    "y_pred = model.predict(test_generator)\n",
    "# Convert predictions from one-hot encoded to class labels\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "# Generate true labels for the test set\n",
    "y_true = test_generator.classes\n",
    "# Generate a classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "# Print the classification report\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4318.894947,
   "end_time": "2023-05-01T14:59:49.077721",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-01T13:47:50.182774",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
