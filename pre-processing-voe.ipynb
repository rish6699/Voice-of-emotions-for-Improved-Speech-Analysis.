{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bc44e7",
   "metadata": {
    "papermill": {
     "duration": 0.004587,
     "end_time": "2023-04-14T18:12:16.020898",
     "exception": false,
     "start_time": "2023-04-14T18:12:16.016311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Performing Resampling , Normalization & Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fbee136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T18:12:16.030566Z",
     "iopub.status.busy": "2023-04-14T18:12:16.030037Z",
     "iopub.status.idle": "2023-04-14T18:14:01.481936Z",
     "shell.execute_reply": "2023-04-14T18:14:01.479660Z"
    },
    "papermill": {
     "duration": 105.461638,
     "end_time": "2023-04-14T18:14:01.486335",
     "exception": false,
     "start_time": "2023-04-14T18:12:16.024697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "INPUT_DIR = \"/kaggle/input/dataset-separated\"\n",
    "OUTPUT_DIR = \"/kaggle/working/dataset-windowed\"\n",
    "SAMPLE_RATE = 22050\n",
    "WINDOW_SIZE = 1.0\n",
    "HOP_SIZE = 0.5\n",
    "\n",
    "# Loop through all the emotion subdirectories\n",
    "for root, dirs, files in os.walk(INPUT_DIR):\n",
    "    for file in files:\n",
    "        # Load the audio file\n",
    "        audio_path = os.path.join(root, file)\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "        # Resample the audio to a common sample rate\n",
    "        audio_resampled = librosa.resample(audio, orig_sr=sr, target_sr=SAMPLE_RATE)\n",
    "\n",
    "        # Normalize the audio data\n",
    "        audio_norm = (audio_resampled - np.mean(audio_resampled)) / np.std(audio_resampled)\n",
    "\n",
    "        # Calculate the number of samples per window\n",
    "        n_samples_per_window = int(WINDOW_SIZE * sr)\n",
    "        # Calculate the number of samples to hop between windows\n",
    "        hop_length = int(HOP_SIZE * sr)\n",
    "\n",
    "        # Loop through the audio signal in overlapping windows\n",
    "        for i in range(0, len(audio_norm) - n_samples_per_window + 1, hop_length):\n",
    "            # Extract the current window\n",
    "            audio_window = audio_norm[i:i+n_samples_per_window]\n",
    "\n",
    "            # Save the windowed audio to a new file\n",
    "            new_audio_path = os.path.join(OUTPUT_DIR, os.path.basename(root), f\"{file}_{i}.wav\")\n",
    "            os.makedirs(os.path.dirname(new_audio_path), exist_ok=True)\n",
    "            sf.write(new_audio_path, audio_window, sr, subtype='PCM_16')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffe510",
   "metadata": {
    "papermill": {
     "duration": 0.003294,
     "end_time": "2023-04-14T18:14:01.493565",
     "exception": false,
     "start_time": "2023-04-14T18:14:01.490271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd4e45b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T18:14:01.504159Z",
     "iopub.status.busy": "2023-04-14T18:14:01.502744Z",
     "iopub.status.idle": "2023-04-14T18:16:19.803049Z",
     "shell.execute_reply": "2023-04-14T18:16:19.800930Z"
    },
    "papermill": {
     "duration": 138.322022,
     "end_time": "2023-04-14T18:16:19.819183",
     "exception": false,
     "start_time": "2023-04-14T18:14:01.497161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [02:18, 15.36s/it]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# Input directory for the windowed audio files\n",
    "INPUT_DIR = \"/kaggle/working/dataset-windowed\"\n",
    "# Output directory for the extracted features\n",
    "OUTPUT_DIR = \"/kaggle/working/features\"\n",
    "\n",
    "# Parameters for MFCC feature extraction\n",
    "N_MFCC = 13\n",
    "N_MELS = 128\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "# Loop through all the emotion subdirectories\n",
    "for root, dirs, files in tqdm(os.walk(INPUT_DIR)):\n",
    "    for file in files:\n",
    "        # Load the audio file\n",
    "        audio_path = os.path.join(root, file)\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "        # Extract MFCC features\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=N_MFCC, n_mels=N_MELS, hop_length=HOP_LENGTH)\n",
    "\n",
    "\n",
    "        # Create a feature vector by taking the mean of MFCC coefficients across time\n",
    "        feature_vector = np.mean(mfcc, axis=1)\n",
    "\n",
    "        # Save the features to a CSV file\n",
    "        output_file = os.path.join(OUTPUT_DIR, os.path.basename(root), f\"{file}.csv\")\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        pd.DataFrame([feature_vector]).to_csv(output_file, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550dad4",
   "metadata": {
    "papermill": {
     "duration": 0.009458,
     "end_time": "2023-04-14T18:16:19.838876",
     "exception": false,
     "start_time": "2023-04-14T18:16:19.829418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Mel Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd815a60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T18:16:19.865543Z",
     "iopub.status.busy": "2023-04-14T18:16:19.863282Z",
     "iopub.status.idle": "2023-04-14T18:30:52.997737Z",
     "shell.execute_reply": "2023-04-14T18:30:52.996194Z"
    },
    "papermill": {
     "duration": 873.152169,
     "end_time": "2023-04-14T18:30:53.002047",
     "exception": false,
     "start_time": "2023-04-14T18:16:19.849878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input and output directories\n",
    "INPUT_DIR = \"/kaggle/working/dataset-windowed\"\n",
    "OUTPUT_DIR = \"/kaggle/working/mel-spectrograms\"\n",
    "\n",
    "# Sampling rate\n",
    "SR = 22050\n",
    "\n",
    "# Number of mel bands\n",
    "N_MELS = 128\n",
    "\n",
    "# Loop through all the emotion subdirectories\n",
    "for root, dirs, files in os.walk(INPUT_DIR):\n",
    "    for file in files:\n",
    "        # Load the audio file\n",
    "        audio_path = os.path.join(root, file)\n",
    "        audio, sr = librosa.load(audio_path, sr=SR)\n",
    "        \n",
    "        # Calculate the mel spectrogram\n",
    "        S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=N_MELS)\n",
    "\n",
    "        # Convert to decibels\n",
    "        log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        # Plot the mel spectrogram\n",
    "        plt.figure(figsize=(5,5))\n",
    "        librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the mel spectrogram\n",
    "        new_audio_path = os.path.join(OUTPUT_DIR, os.path.basename(root), f\"{file}.png\")\n",
    "        os.makedirs(os.path.dirname(new_audio_path), exist_ok=True)\n",
    "        plt.savefig(new_audio_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d6c31",
   "metadata": {
    "papermill": {
     "duration": 0.006318,
     "end_time": "2023-04-14T18:30:53.014622",
     "exception": false,
     "start_time": "2023-04-14T18:30:53.008304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LABEL CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3124145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T18:30:53.029381Z",
     "iopub.status.busy": "2023-04-14T18:30:53.028807Z",
     "iopub.status.idle": "2023-04-14T18:30:53.102151Z",
     "shell.execute_reply": "2023-04-14T18:30:53.100792Z"
    },
    "papermill": {
     "duration": 0.084697,
     "end_time": "2023-04-14T18:30:53.105510",
     "exception": false,
     "start_time": "2023-04-14T18:30:53.020813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Path to directory containing the mel-spectrograms\n",
    "INPUT_DIR = \"/kaggle/working/mel-spectrograms\"\n",
    "\n",
    "# Create a list of all the mel-spectrogram file paths\n",
    "mel_files = []\n",
    "for root, dirs, files in os.walk(INPUT_DIR):\n",
    "    for file in files:\n",
    "        mel_path = os.path.join(root, file)\n",
    "        #print(mel_path)\n",
    "        mel_files.append(mel_path)\n",
    "\n",
    "# Define the emotions corresponding to each identifier\n",
    "emotions = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "# Define the labels file path\n",
    "LABELS_FILE = \"labels.csv\"\n",
    "\n",
    "# Open the labels file for writing\n",
    "with open(LABELS_FILE, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"file_name\", \"emotion\"])\n",
    "\n",
    "    # Iterate over the mel-spectrogram file paths\n",
    "    for mel_file in mel_files:\n",
    "        # Extract the file name and the emotion from the file path\n",
    "        file_name = os.path.basename(mel_file).split(\".\")[0] + \".png\"\n",
    "        file_name_parts = file_name.split(\"_\")\n",
    "        #print(file_name_parts)\n",
    "        emotion_id = file_name_parts[0].split(\"-\")[2]\n",
    "        emotion = emotions[emotion_id]\n",
    "\n",
    "        # Extract the folder containing the png file and append it to the file path\n",
    "        folder = emotion\n",
    "        png_file =  file_name\n",
    "        #print(png_file)\n",
    "        # Write the file name and emotion to the labels file\n",
    "        writer.writerow([png_file, emotion])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588d0971",
   "metadata": {
    "papermill": {
     "duration": 0.004173,
     "end_time": "2023-04-14T18:30:53.114165",
     "exception": false,
     "start_time": "2023-04-14T18:30:53.109992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64c17a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T18:30:53.126065Z",
     "iopub.status.busy": "2023-04-14T18:30:53.124693Z",
     "iopub.status.idle": "2023-04-14T18:30:54.014365Z",
     "shell.execute_reply": "2023-04-14T18:30:54.013217Z"
    },
    "papermill": {
     "duration": 0.898869,
     "end_time": "2023-04-14T18:30:54.017408",
     "exception": false,
     "start_time": "2023-04-14T18:30:53.118539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Input and output directories\n",
    "INPUT_DIR = \"/kaggle/working/mel-spectrograms\"\n",
    "OUTPUT_DIR = \"/kaggle/working/dataset-split\"\n",
    "\n",
    "# Training, validation, and test set sizes\n",
    "TRAIN_SIZE = 0.7\n",
    "VAL_SIZE = 0.2\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "# Seed for random number generator\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Loop through all the emotion subdirectories\n",
    "for root, dirs, files in os.walk(INPUT_DIR):\n",
    "    # Shuffle the file list\n",
    "    random.seed(RANDOM_SEED)\n",
    "    random.shuffle(files)\n",
    "\n",
    "    # Calculate the number of files for each set\n",
    "    n_files = len(files)\n",
    "    n_train = int(n_files * TRAIN_SIZE)\n",
    "    n_val = int(n_files * VAL_SIZE)\n",
    "    n_test = n_files - n_train - n_val\n",
    "\n",
    "    # Split the files into sets\n",
    "    train_files = files[:n_train]\n",
    "    val_files = files[n_train:n_train+n_val]\n",
    "    test_files = files[n_train+n_val:]\n",
    "\n",
    "    # Copy the files to their respective sets\n",
    "    for file in train_files:\n",
    "        src_path = os.path.join(root, file)\n",
    "        dst_dir = os.path.join(OUTPUT_DIR, \"train\", os.path.basename(root))\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        dst_path = os.path.join(dst_dir, file)\n",
    "        shutil.copyfile(src_path, dst_path)\n",
    "\n",
    "    for file in val_files:\n",
    "        src_path = os.path.join(root, file)\n",
    "        dst_dir = os.path.join(OUTPUT_DIR, \"val\", os.path.basename(root))\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        dst_path = os.path.join(dst_dir, file)\n",
    "        shutil.copyfile(src_path, dst_path)\n",
    "\n",
    "    for file in test_files:\n",
    "        src_path = os.path.join(root, file)\n",
    "        dst_dir = os.path.join(OUTPUT_DIR, \"test\", os.path.basename(root))\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        dst_path = os.path.join(dst_dir, file)\n",
    "        shutil.copyfile(src_path, dst_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1133.523495,
   "end_time": "2023-04-14T18:30:57.352180",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-14T18:12:03.828685",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
